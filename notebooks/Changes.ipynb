{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, input_file_name, to_date, to_timestamp, regexp_extract\n",
    "from pyspark.sql.types import MapType, StringType, StructField, StructType\n",
    "\n",
    "from lib.spark import get_spark_session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: fs.s3a.aws.credentials.provider\n",
      "22/05/19 13:57:21 WARN Utils: Your hostname, Jordans-MacBook-Pro-2.local resolves to a loopback address: 127.0.0.1; using 10.0.0.140 instead (on interface en0)\n",
      "22/05/19 13:57:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /Users/jordan.yaker/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/jordan.yaker/.ivy2/jars\n",
      "com.databricks#spark-xml_2.12 added as a dependency\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "org.apache.spark#spark-streaming-kinesis-asl_2.12 added as a dependency\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a638dc95-a749-4de3-aea6-74c85adac974;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.databricks#spark-xml_2.12;0.14.0 in central\n",
      "\tfound commons-io#commons-io;2.8.0 in central\n",
      "\tfound org.glassfish.jaxb#txw2;2.3.4 in central\n",
      "\tfound org.apache.ws.xmlschema#xmlschema-core;2.2.5 in central\n",
      "\tfound io.delta#delta-core_2.12;1.2.1 in central\n",
      "\tfound io.delta#delta-storage;1.2.1 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.1 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.901 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound org.apache.spark#spark-streaming-kinesis-asl_2.12;3.2.1 in central\n",
      "\tfound com.amazonaws#amazon-kinesis-client;1.12.0 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-dynamodb;1.11.655 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-s3;1.11.655 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kms;1.11.655 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-core;1.11.655 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.14 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound software.amazon.ion#ion-java;1.0.2 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.12.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.12.3 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.12.3 in central\n",
      "\tfound joda-time#joda-time;2.10.10 in central\n",
      "\tfound com.amazonaws#jmespath-java;1.11.655 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-kinesis;1.11.655 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-cloudwatch;1.11.655 in central\n",
      "\tfound com.google.guava#guava;14.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.12.0 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-sts;1.11.655 in central\n",
      "\tfound com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.12.3 in central\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in central\n",
      "\tfound org.postgresql#postgresql;42.3.5 in central\n",
      "\tfound org.checkerframework#checker-qual;3.5.0 in central\n",
      ":: resolution report :: resolve 845ms :: artifacts dl 112ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#amazon-kinesis-client;1.12.0 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-cloudwatch;1.11.655 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-core;1.11.655 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-dynamodb;1.11.655 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kinesis;1.11.655 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-kms;1.11.655 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-s3;1.11.655 from central in [default]\n",
      "\tcom.amazonaws#aws-java-sdk-sts;1.11.655 from central in [default]\n",
      "\tcom.amazonaws#jmespath-java;1.11.655 from central in [default]\n",
      "\tcom.databricks#spark-xml_2.12;0.14.0 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.12.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.12.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.12.3 from central in [default]\n",
      "\tcom.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.12.3 from central in [default]\n",
      "\tcom.google.guava#guava;14.0.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-io#commons-io;2.8.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tio.delta#delta-core_2.12;1.2.1 from central in [default]\n",
      "\tio.delta#delta-storage;1.2.1 from central in [default]\n",
      "\tjoda-time#joda-time;2.10.10 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.12.0 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.1 from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.14 from central in [default]\n",
      "\torg.apache.spark#spark-streaming-kinesis-asl_2.12;3.2.1 from central in [default]\n",
      "\torg.apache.ws.xmlschema#xmlschema-core;2.2.5 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.5.0 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.glassfish.jaxb#txw2;2.3.4 from central in [default]\n",
      "\torg.postgresql#postgresql;42.3.5 from central in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\tsoftware.amazon.ion#ion-java;1.0.2 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.6.7 by [com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.12.3] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   38  |   0   |   0   |   1   ||   37  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a638dc95-a749-4de3-aea6-74c85adac974\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 37 already retrieved (0kB/15ms)\n",
      "22/05/19 13:57:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = get_spark_session(driver=\"spark://localhost:7077\")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = \"s3a://oc-dev-internal-data-lake-kinesis-cdc/\"\n",
    "INPUT_PATH_REGEX = r\"s3a:\\/\\/oc-dev-internal-data-lake-kinesis-cdc\\/([a-zA-Z0-9_]+?)\\/([a-zA-Z0-9\\-]+?)\\/.*\"\n",
    "INPUT_SCHEMA = StructType([\n",
    "    StructField(\"data\", MapType(StringType(), StringType()), False),\n",
    "    StructField(\"metadata\", MapType(StringType(), StringType()), False)\n",
    "])\n",
    "\n",
    "OUTPUT_PATH = \"s3a://oc-dev-internal-data-lake-bronze/changes/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = spark.read.json(INPUT_PATH, INPUT_SCHEMA, recursiveFileLookup=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = input.withColumn(\"filename\", input_file_name()) \\\n",
    "          .select(regexp_extract(\"filename\", INPUT_PATH_REGEX, 2).cast(\"date\").alias(\"day_id\"),\n",
    "                  regexp_extract(\"filename\", INPUT_PATH_REGEX, 1).alias(\"table_name\"),\n",
    "                  to_timestamp(col(\"metadata\")['timestamp'], \"yyyy-MM-dd'T'HH:mm:ss.SSSSSSVV\").alias(\"timestamp\"),\n",
    "                  \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write \\\n",
    "  .format(\"delta\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .save(OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
